{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34ca1132-4b11-4b11-87ad-f267c83b1ef0",
   "metadata": {},
   "source": [
    "# Email classification(spam or not spam)\n",
    "- Evaluation metrics: accuracy, precision, recall, and F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3348b7f0-ac7b-4485-9bd8-89c8998a2eea",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "- Total of 100 emails\n",
    "- 80 emails are legitimate(non-spam)\n",
    "- 20 emails are spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e7abe9-efda-41f8-b2fb-30ffdb87d38b",
   "metadata": {},
   "source": [
    "## Model\n",
    "- Identifies 15 spam emails\n",
    "- 10 correct, 5 mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277acee9-0328-4b00-9d1e-5fa71f5c9f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b6508d2-4633-4a90-a784-c8fb4ba1a27b",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "- The proportion of correctly predicted observations to the total predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1039856c-6f0c-46e8-b0d7-90daee9b528b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85\n"
     ]
    }
   ],
   "source": [
    "true_positives = 10 # correctly identified as spam\n",
    "true_negatives = 75 # correctly identified as non-spam\n",
    "total_predictions = 100\n",
    "accuracy = (true_positives + true_negatives) / total_predictions # (10+75) / 100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88293933-8552-41cf-b270-244cc4dc2e48",
   "metadata": {},
   "source": [
    "### Precision\n",
    "- Out of all the predictions our model labeled as positive, how many were truly positive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2987c321-d23f-4166-b25b-40cf6a8f81f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "true_positives = 10 # correctly identified as spam\n",
    "false_positives = 5 # mistakenly identified as spam\n",
    "precision = true_positives / (true_positives + false_positives) # 10 / (10+5)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9313bb6b-f143-4858-b9d6-ecd8cd48dcbc",
   "metadata": {},
   "source": [
    "### Recall\n",
    "- Also known as sensitivity\n",
    "- Out of all the actual positives, how many did the model correctly identify?\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68b9ca30-bbcc-46be-880e-bd899ade8376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "true_positives = 10 # correctly identified as spam\n",
    "false_negatives = 10 # mistakenly identified as non-spam\n",
    "recall = true_positives / (true_positives + false_negatives) # 10 / (10 + 10)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f96297-c9b6-4065-982f-2750d8a888af",
   "metadata": {},
   "source": [
    "### F1-Score\n",
    "- Combines precision and recall into one metric\n",
    "- Harmonic mean of precision and recall\n",
    "- Useful when you need to balance precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9bb3a17-ca6d-4837-ae69-0e9da26dc90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714285714285715\n"
     ]
    }
   ],
   "source": [
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebbd32e-9c73-459e-bcfe-9ab20adac11a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
